# Parquet Data
- Parquet is a columnar storage file format that is optimized for use in Big Data processing frameworks such as Apache Hadoop, Apache Spark and Apache Hive.
- Parquet files are designed to efficiently store and process large amounts of structured data. 
- The file format is optimized for compression, which reduces the storage footprint and can speed up processing by reducing the amount of data that needs to be read from disk.
- In addition to compression, Parquet supports various encoding schemes, such as dictionary encoding and run-length encoding, which can further reduce the amount of storage and processing required.
- Parquet files also support nested data structures and complex data types, which makes them ideal for handling structured data that has many fields or complex relationships between fields.
- Overall, Parquet files are a highly efficient and flexible way to store and process large amounts of structured data in distributed computing environments.

# ORC (Optimized Row Columnar) 
- It is another columnar storage file format that is designed for storing and processing large amounts of structured data in distributed computing environments. 
- Like Parquet, ORC is also optimized for compression and encoding to minimize storage and processing requirements.
- ORC provides greater compression than Parquet.

# Parquet vs ORC
- Apache Spark works well with Parqurt file format
- Apache Hive works well with ORC file format

## Key features

### Columnar storage: 
- ORC stores data in columnar format, which means that values of the same column are stored together. 
- This enables faster processing of queries that only need to access specific columns.

### Type evolution: 
- ORC allows schema evolution, which means that you can add, remove or modify columns without having to rewrite the entire data set.

### Indexing: 
- ORC supports various indexing schemes such as Bloom filters and min/max indexes to speed up query processing.

# To create a Parquet/ORC table using another table

## Step #1
- Create a table in Hive with the desired schema. 
- For example, let's say we want to create a table called "users" with the following schema:
```
CREATE TABLE users
(
  id INT,
  name STRING,
  email STRING,
  age INT
);
```

## Step #2
- Load some data into the table using the INSERT INTO statement
```
INSERT INTO users VALUES
  (1, 'John', 'john@example.com', 30),
  (2, 'Jane', 'jane@example.com', 25),
  (3, 'Bob', 'bob@example.com', 40);
```

## Step #3
- Create the schema for the Parquet table
```
CREATE TABLE users_parquet
(
  id INT,
  name STRING,
  email STRING,
  age INT
)
STORED AS PARQUET;
```

- Create the schema for the ORC table
```
CREATE TABLE users_orc
(
  id INT,
  name STRING,
  email STRING,
  age INT
)
STORED AS ORC;
```

# Step #4
- Use the ```INSERT OVERWRITE TABLE``` statement to copy data from 'users' table & write the data in Parquet format.
```
FROM users
INSERT OVERWRITE TABLE users_parquet
SELECT *;
```

- Use the ```INSERT OVERWRITE TABLE``` statement to copy data from 'users' table & write the data in ORC format.
```
FROM users
INSERT OVERWRITE TABLE users_orc
SELECT *;
```
